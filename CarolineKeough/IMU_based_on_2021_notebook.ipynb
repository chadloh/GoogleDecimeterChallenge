{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "IMU based on 2021 notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eYtZDtCU0o73",
        "yp4o3x7M0o77"
      ],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chadloh/GoogleDecimeterChallenge/blob/main/CarolineKeough/IMU_based_on_2021_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Next Point with the IMU Data\n",
        "Author: **Alvin.ai**<br>\n",
        "IMU is Inertial Measurement Unit, whicn involves accelerometer, gyroscope asn so on. In Microsoft Research's Indoor Location & Navigation Competition, many kagglers used the IMU Data. In recent days, I attempted to build a model to utilize the given sensors' data and I found that it works for me as below:<br>\n",
        "1. Reject Outlier + KF Smooth + Phone Mean: LB-**5.653**\n",
        "2. **IMU Prediction** + Reject Outlier + KF Smooth + Phone Mean: LB-**5.476**\n",
        "\n",
        "What I do is to simple, **use historical points with sensors' dataset to predict where the next point is.**<br>\n",
        "Talk is cheap, show you the code. Hope it is helpful to you.<br>\n",
        "By the way, **I am looking forward to find a teammates, if you're interested, pls see the end of this kernal.**<br>\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "Aa_-CiD10o7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7livR45i0ugW",
        "outputId": "465c7be3-512a-4eec-e1e1-0243ebbb7a50"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyproj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgwA7JZg1GpU",
        "outputId": "5d4181fd-bd73-47ae-b0da-98d8f525baf7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyproj\n",
            "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 16.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from pyproj) (2022.6.15)\n",
            "Installing collected packages: pyproj\n",
            "Successfully installed pyproj-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from cv2 import Rodrigues\n",
        "from math import sin, cos, atan2, sqrt\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import pyproj\n",
        "from pyproj import Proj, transform\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
        "from sklearn.metrics import accuracy_score\n",
        "import lightgbm as lgb\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import itertools\n",
        "warnings.filterwarnings(\"ignore\", category=Warning)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T08:46:50.972041Z",
          "iopub.execute_input": "2021-07-03T08:46:50.972594Z",
          "iopub.status.idle": "2021-07-03T08:46:53.680924Z",
          "shell.execute_reply.started": "2021-07-03T08:46:50.972482Z",
          "shell.execute_reply": "2021-07-03T08:46:53.679998Z"
        },
        "trusted": true,
        "id": "GRwDzUqb0o7s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select files to train. Try to have different locations, routes, phones\n",
        "#LAX, MTV, SJC, SVL, SFO\n",
        "\n",
        "data_dir = Path('/content/drive/MyDrive/Google_decimeter/smartphone-decimeter-2022')\n",
        "\n",
        "train1 = Path('2021-12-28-US-MTV-1/SamsungGalaxyS20Ultra')\n",
        "train2 = Path('2021-12-15-US-MTV-1/GooglePixel5')\n",
        "train3 = Path('2021-12-09-US-LAX-2/GooglePixel6Pro')\n",
        "train4 = Path('2021-12-08-US-LAX-5/XiaomiMi8')\n",
        "train5 = Path('2021-08-24-US-SVL-1/GooglePixel4')\n",
        "train6 = Path('2021-08-04-US-SJC-1/GooglePixel5')\n",
        "train7 = Path('2021-07-27-US-MTV-1/XiaomiMi8')\n",
        "train8 = Path('2021-04-26-US-SVL-2/SamsungGalaxyS20Ultra')\n",
        "train9 = Path('2021-04-29-US-MTV-2/SamsungGalaxyS20Ultra')\n",
        "train10 = Path('2021-01-04-US-SFO-2/GooglePixel5') #this one won't have orientation deg"
      ],
      "metadata": {
        "id": "0zgicsh22ezc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(data_dir / 'train' / train3 / 'supplemental' / 'gnss_log.txt', sep = ' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IvvaTc_BuP4e",
        "outputId": "e1255960-5615-4fa3-f9b1-b06e1478eefa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e7569820a777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtrain9\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'supplemental'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'gnss_log.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 3 fields in line 4, saw 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#select test files. as in from train folder. but to test the model\n",
        "test1 = Path('2021-12-07-US-LAX-1/GooglePixel5')\n",
        "test2 = Path('2021-07-14-US-MTV-1/SamsungGalaxyS20Ultra')\n",
        "\n",
        "test_sets = [test1, test2]"
      ],
      "metadata": {
        "id": "Mo3E6OTp0Lyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this was an attempt to do list append instead of df concat\n",
        "\n",
        "# list_of_training_sets = [train1, train2]#, 'train3', 'train4', 'train5',\\\n",
        "#                         # 'train6', 'train7', 'train8', 'train9', 'train10']\n",
        "\n",
        "# # def get_bls(list_of_training_sets):\n",
        "# # bl_trn_df = pd.DataFrame(columns = ['collectionName', 'phoneName','utctimeMillis', 'Xbl', 'Ybl', 'Zbl'])\n",
        "# collectionName =[]\n",
        "# phoneName = []\n",
        "# utcTimeMillis = []\n",
        "# Xbl = []\n",
        "# Ybl = []\n",
        "# Zbl = []\n",
        "\n",
        "# for train in list_of_training_sets:\n",
        "#   device_gnss = pd.read_csv(data_dir / train / 'device_gnss.csv')\\\n",
        "#   [['utcTimeMillis', 'WlsPositionXEcefMeters','WlsPositionYEcefMeters', 'WlsPositionZEcefMeters']]\n",
        "#   device_gnss = device_gnss.drop_duplicates().reset_index().drop(columns = 'index')\n",
        "#   device_gnss = device_gnss.rename(columns = {'WlsPositionXEcefMeters':'Xbl',\\\n",
        "#                 'WlsPositionYEcefMeters':'Ybl', 'WlsPositionZEcefMeters': 'Ybl'}) \n",
        "#   utcTimeMillis.append(device_gnss['utcTimeMillis'])\n",
        "#   collectionName.append([str(train).split('/')[0]]*len(device_gnss))\n",
        "#   phoneName.append([str(train).split('/')[1]]*len(device_gnss))\n",
        "#   Xbl.append(device_gnss[])\n",
        "#   # bl_trn_df = pd.concat([bl_trn_df, bl], axis = 0)\n",
        "#   #do I need to set_index('collectionName')???\n",
        "# bl_trn_df = pd.DataFrame(list(zip(collectionName, phoneName, utcTimeMillis, Xbl, Ybl, Zbl)))\n"
      ],
      "metadata": {
        "id": "M3XkgW2T42RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#internet said not to concat dfs but i'm gonna try\n",
        "training_sets = [train1, train2, train3, train4, train5,\\\n",
        "                         train6, train7, train8, train9, train10]\n",
        "\n",
        "def get_bls(list_of_training_sets):\n",
        "  bl_trn_df = pd.DataFrame(columns = ['collectionName', 'phoneName','utcTimeMillis', 'Xbl', 'Ybl', 'Zbl'])\n",
        "\n",
        "  for train in list_of_training_sets:\n",
        "    #just updated line below hopefully still works\n",
        "    device_gnss = pd.read_csv(data_dir / 'train' / train / 'device_gnss.csv')\\\n",
        "    [['utcTimeMillis', 'WlsPositionXEcefMeters','WlsPositionYEcefMeters', 'WlsPositionZEcefMeters']]\n",
        "    device_gnss = device_gnss.drop_duplicates().reset_index().drop(columns = 'index')\n",
        "    device_gnss = device_gnss.rename(columns = {'WlsPositionXEcefMeters':'Xbl',\\\n",
        "                  'WlsPositionYEcefMeters':'Ybl', 'WlsPositionZEcefMeters': 'Zbl'}) \n",
        "    collectionName = pd.Series([str(train).split('/')[0]]*len(device_gnss), name = 'collectionName')\n",
        "    phoneName = pd.Series([str(train).split('/')[1]]*len(device_gnss), name = 'phoneName')\n",
        "    bl = pd.concat([collectionName, phoneName, device_gnss], axis = 1)\n",
        "    bl_trn_df = pd.concat([bl_trn_df, bl], axis = 0, ignore_index = True)\n",
        "  return bl_trn_df\n"
      ],
      "metadata": {
        "id": "-mGHAD92OOtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bl_trn_df = get_bls(training_sets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QVTP6VbSRQ51",
        "outputId": "f972b242-3232-4d27-aebc-46c3fde7677c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            collectionName              phoneName  utcTimeMillis  \\\n",
              "0      2021-12-28-US-MTV-1  SamsungGalaxyS20Ultra  1640722632000   \n",
              "1      2021-12-28-US-MTV-1  SamsungGalaxyS20Ultra  1640722633000   \n",
              "2      2021-12-28-US-MTV-1  SamsungGalaxyS20Ultra  1640722634000   \n",
              "3      2021-12-28-US-MTV-1  SamsungGalaxyS20Ultra  1640722635000   \n",
              "4      2021-12-28-US-MTV-1  SamsungGalaxyS20Ultra  1640722636000   \n",
              "...                    ...                    ...            ...   \n",
              "18153  2021-01-04-US-SFO-2           GooglePixel5  1609801853433   \n",
              "18154  2021-01-04-US-SFO-2           GooglePixel5  1609801854433   \n",
              "18155  2021-01-04-US-SFO-2           GooglePixel5  1609801855433   \n",
              "18156  2021-01-04-US-SFO-2           GooglePixel5  1609801856433   \n",
              "18157  2021-01-04-US-SFO-2           GooglePixel5  1609801857433   \n",
              "\n",
              "                Xbl           Ybl           Zbl  \n",
              "0     -2.693857e+06 -4.297547e+06  3.854144e+06  \n",
              "1     -2.693856e+06 -4.297544e+06  3.854144e+06  \n",
              "2     -2.693855e+06 -4.297539e+06  3.854143e+06  \n",
              "3     -2.693860e+06 -4.297547e+06  3.854146e+06  \n",
              "4     -2.693858e+06 -4.297548e+06  3.854148e+06  \n",
              "...             ...           ...           ...  \n",
              "18153 -2.704197e+06 -4.288807e+06  3.856680e+06  \n",
              "18154 -2.704197e+06 -4.288810e+06  3.856682e+06  \n",
              "18155 -2.704196e+06 -4.288806e+06  3.856680e+06  \n",
              "18156 -2.704196e+06 -4.288804e+06  3.856678e+06  \n",
              "18157 -2.704196e+06 -4.288806e+06  3.856679e+06  \n",
              "\n",
              "[18158 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3184945f-e025-4363-9685-be83aa7487ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>collectionName</th>\n",
              "      <th>phoneName</th>\n",
              "      <th>utcTimeMillis</th>\n",
              "      <th>Xbl</th>\n",
              "      <th>Ybl</th>\n",
              "      <th>Zbl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-12-28-US-MTV-1</td>\n",
              "      <td>SamsungGalaxyS20Ultra</td>\n",
              "      <td>1640722632000</td>\n",
              "      <td>-2.693857e+06</td>\n",
              "      <td>-4.297547e+06</td>\n",
              "      <td>3.854144e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-12-28-US-MTV-1</td>\n",
              "      <td>SamsungGalaxyS20Ultra</td>\n",
              "      <td>1640722633000</td>\n",
              "      <td>-2.693856e+06</td>\n",
              "      <td>-4.297544e+06</td>\n",
              "      <td>3.854144e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-12-28-US-MTV-1</td>\n",
              "      <td>SamsungGalaxyS20Ultra</td>\n",
              "      <td>1640722634000</td>\n",
              "      <td>-2.693855e+06</td>\n",
              "      <td>-4.297539e+06</td>\n",
              "      <td>3.854143e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-12-28-US-MTV-1</td>\n",
              "      <td>SamsungGalaxyS20Ultra</td>\n",
              "      <td>1640722635000</td>\n",
              "      <td>-2.693860e+06</td>\n",
              "      <td>-4.297547e+06</td>\n",
              "      <td>3.854146e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-12-28-US-MTV-1</td>\n",
              "      <td>SamsungGalaxyS20Ultra</td>\n",
              "      <td>1640722636000</td>\n",
              "      <td>-2.693858e+06</td>\n",
              "      <td>-4.297548e+06</td>\n",
              "      <td>3.854148e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18153</th>\n",
              "      <td>2021-01-04-US-SFO-2</td>\n",
              "      <td>GooglePixel5</td>\n",
              "      <td>1609801853433</td>\n",
              "      <td>-2.704197e+06</td>\n",
              "      <td>-4.288807e+06</td>\n",
              "      <td>3.856680e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18154</th>\n",
              "      <td>2021-01-04-US-SFO-2</td>\n",
              "      <td>GooglePixel5</td>\n",
              "      <td>1609801854433</td>\n",
              "      <td>-2.704197e+06</td>\n",
              "      <td>-4.288810e+06</td>\n",
              "      <td>3.856682e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18155</th>\n",
              "      <td>2021-01-04-US-SFO-2</td>\n",
              "      <td>GooglePixel5</td>\n",
              "      <td>1609801855433</td>\n",
              "      <td>-2.704196e+06</td>\n",
              "      <td>-4.288806e+06</td>\n",
              "      <td>3.856680e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18156</th>\n",
              "      <td>2021-01-04-US-SFO-2</td>\n",
              "      <td>GooglePixel5</td>\n",
              "      <td>1609801856433</td>\n",
              "      <td>-2.704196e+06</td>\n",
              "      <td>-4.288804e+06</td>\n",
              "      <td>3.856678e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18157</th>\n",
              "      <td>2021-01-04-US-SFO-2</td>\n",
              "      <td>GooglePixel5</td>\n",
              "      <td>1609801857433</td>\n",
              "      <td>-2.704196e+06</td>\n",
              "      <td>-4.288806e+06</td>\n",
              "      <td>3.856679e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18158 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3184945f-e025-4363-9685-be83aa7487ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3184945f-e025-4363-9685-be83aa7487ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3184945f-e025-4363-9685-be83aa7487ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bl_tst_df = get_bls(test_sets)"
      ],
      "metadata": {
        "id": "xGsiTnBj0r-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_dir = Path(\"../input/google-smartphone-decimeter-challenge\")\n",
        "# bl_trn_fname = 'baseline_locations_train.csv'\n",
        "# bl_tst_fname = 'baseline_locations_test.csv'\n",
        "# sample_fname = 'sample_submission.csv'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T08:47:59.104157Z",
          "iopub.execute_input": "2021-07-03T08:47:59.104548Z",
          "iopub.status.idle": "2021-07-03T08:47:59.108794Z",
          "shell.execute_reply.started": "2021-07-03T08:47:59.104516Z",
          "shell.execute_reply": "2021-07-03T08:47:59.107999Z"
        },
        "trusted": true,
        "id": "Bo-IUCjw0o7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bl_trn_df = pd.read_csv(data_dir / bl_trn_fname)\n",
        "# bl_tst_df = pd.read_csv(data_dir / bl_tst_fname)\n",
        "\n",
        "\n",
        "#FLAG do i need to do sample df\n",
        "# sample_df = pd.read_csv(data_dir / sample_fname)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T08:47:59.525093Z",
          "iopub.execute_input": "2021-07-03T08:47:59.52563Z",
          "iopub.status.idle": "2021-07-03T08:48:00.201846Z",
          "shell.execute_reply.started": "2021-07-03T08:47:59.525595Z",
          "shell.execute_reply": "2021-07-03T08:48:00.200775Z"
        },
        "trusted": true,
        "id": "CctCkV780o7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print('Baseline Train shape:', bl_trn_df.shape)\n",
        "# print('Baseline Test shape:', bl_tst_df.shape)\n",
        "# print('Test shape:', sample_df.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T08:48:29.17167Z",
          "iopub.execute_input": "2021-07-03T08:48:29.172037Z",
          "iopub.status.idle": "2021-07-03T08:48:29.177571Z",
          "shell.execute_reply.started": "2021-07-03T08:48:29.171986Z",
          "shell.execute_reply": "2021-07-03T08:48:29.176397Z"
        },
        "trusted": true,
        "id": "_G2A3h7d0o7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Euler Angles to Rotation Vector\n",
        "Euler Angles <-> Rotation Matrix <-> Rotation Vector<br>\n",
        "More info.:[About IMU: OrientationDeg to Rotation Vector](https://www.kaggle.com/c/google-smartphone-decimeter-challenge/discussion/247834)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T08:49:08.128564Z",
          "iopub.execute_input": "2021-07-03T08:49:08.129017Z",
          "iopub.status.idle": "2021-07-03T08:49:08.134112Z",
          "shell.execute_reply.started": "2021-07-03T08:49:08.128971Z",
          "shell.execute_reply": "2021-07-03T08:49:08.132931Z"
        },
        "id": "yspzbZ9j0o7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pitch:y\n",
        "# yaw:z\n",
        "# roll:x\n",
        "def an2v(y_delta, z_delta, x_delta):\n",
        "    '''\n",
        "    Euler Angles ->Rotation Matrix -> Rotation Vector\n",
        "\n",
        "    Input：\n",
        "        1. y_delta          (float): the angle with rotateing around y-axis.\n",
        "        2. z_delta         (float): the angle with rotateing around z-axis. \n",
        "        3. x_delta         (float): the angle with rotateing around x-axis. \n",
        "    Output：\n",
        "        rx/ry/rz             (float): the rotation vector with rotateing \n",
        "    \n",
        "    Code Ref.: https://www.zacobria.com/universal-robots-knowledge-base-tech-support-forum-hints-tips/python-code-example-of-converting-rpyeuler-angles-to-rotation-vectorangle-axis-for-universal-robots/\n",
        "    (Note：In Code Ref: pitch=y,yaw=z,roll=x. But Google is pitch=x,yaw=z,roll=y)\n",
        "    '''\n",
        "    # yaw: z\n",
        "    Rz_Matrix = np.matrix([\n",
        "    [math.cos(z_delta), -math.sin(z_delta), 0],\n",
        "    [math.sin(z_delta), math.cos(z_delta), 0],\n",
        "    [0, 0, 1]\n",
        "    ])\n",
        "    \n",
        "    # pitch: y\n",
        "    Ry_Matrix = np.matrix([\n",
        "    [math.cos(y_delta), 0, math.sin(y_delta)],\n",
        "    [0, 1, 0],\n",
        "    [-math.sin(y_delta), 0, math.cos(y_delta)]\n",
        "    ])\n",
        "    \n",
        "    # roll: x\n",
        "    Rx_Matrix = np.matrix([\n",
        "    [1, 0, 0],\n",
        "    [0, math.cos(x_delta), -math.sin(x_delta)],\n",
        "    [0, math.sin(x_delta), math.cos(x_delta)]\n",
        "    ])\n",
        "\n",
        "    R = Rz_Matrix * Ry_Matrix * Rx_Matrix\n",
        "\n",
        "    theta = math.acos(((R[0, 0] + R[1, 1] + R[2, 2]) - 1) / 2)\n",
        "    multi = 1 / (2 * math.sin(theta))\n",
        "\n",
        "    rx = multi * (R[2, 1] - R[1, 2]) * theta\n",
        "    ry = multi * (R[0, 2] - R[2, 0]) * theta\n",
        "    rz = multi * (R[1, 0] - R[0, 1]) * theta\n",
        "\n",
        "    return rx, ry, rz"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T08:51:34.928845Z",
          "iopub.execute_input": "2021-07-03T08:51:34.9294Z",
          "iopub.status.idle": "2021-07-03T08:51:34.943381Z",
          "shell.execute_reply.started": "2021-07-03T08:51:34.929355Z",
          "shell.execute_reply": "2021-07-03T08:51:34.941748Z"
        },
        "trusted": true,
        "id": "sBImbYys0o7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def v2a(rotation_v):\n",
        "    '''\n",
        "    Rotation Vector -> Rotation Matrix -> Euler Angles\n",
        "\n",
        "    Input：\n",
        "        rx/ry/rz             (float): the rotation vector with rotateing around x/y/z-axis.\n",
        "    Output：\n",
        "        1. y_delta          (float): the angle with rotateing around y-axis.\n",
        "        2. z_delta         (float): the angle with rotateing around z-axis. \n",
        "        3. x_delta         (float): the angle with rotateing around x-axis.  \n",
        "    '''\n",
        "    # Rotation Vector -> Rotation Matrix\n",
        "    R = Rodrigues(rotation_v)[0]\n",
        "\n",
        "    sq = sqrt(R[2,1] ** 2 +  R[2,2] ** 2)\n",
        "\n",
        "    if  not (sq < 1e-6) :\n",
        "        x_delta = atan2(R[2,1] , R[2,2])\n",
        "        y_delta = atan2(-R[2,0], sq)\n",
        "        z_delta = atan2(R[1,0], R[0,0])\n",
        "    else :\n",
        "        x_delta = atan2(-R[1,2], R[1,1])\n",
        "        y_delta = atan2(-R[2,0], sq)\n",
        "        z_delta = 0\n",
        "\n",
        "    return y_delta, z_delta, x_delta"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T08:52:07.356293Z",
          "iopub.execute_input": "2021-07-03T08:52:07.356686Z",
          "iopub.status.idle": "2021-07-03T08:52:07.363908Z",
          "shell.execute_reply.started": "2021-07-03T08:52:07.356652Z",
          "shell.execute_reply": "2021-07-03T08:52:07.362834Z"
        },
        "trusted": true,
        "id": "kJq4ujV70o7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prepare IMU Dataset\n",
        "This part is to prepare the dataset for the model. I divided this part into the following steps:<br>\n",
        "(1) **Load GNSS Log**<br>\n",
        "(2) **Merge sub-dataset** (Status/UncalAccel/UncalGyro/UncalMag/OrientationDeg)<br>\n",
        "(3) **UTC to GpsEpoch**<br>\n",
        "(4) **OrientationDeg to Rotation Vecto**r<br>\n",
        "(5) **Calibrate Sensors' data**<br>\n",
        "(6) **LatDeg&lngDeg to x/y/z**<br>\n",
        "(7) **Orgainze Data** (eg. t1 t2 t3 t4 t5 -> t6)<br>\n",
        "(8) **Clean Data** (unrelated-aixs features and uncalibrated features)<br>\n",
        "(9) **Add Statistic Features**"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:01:39.921887Z",
          "iopub.execute_input": "2021-07-03T09:01:39.922246Z",
          "iopub.status.idle": "2021-07-03T09:01:39.930463Z",
          "shell.execute_reply.started": "2021-07-03T09:01:39.922217Z",
          "shell.execute_reply": "2021-07-03T09:01:39.92891Z"
        },
        "id": "Cwy72duc0o7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # gnss_log_to_dataframes(str(data_dir / 'train' / tgt_cns[0] / pns[0] / 'supplemental' / 'gnss_log.txt'))\n",
        "# # data_dir, 'train', tgt_cns[0], pns[0], bl_trn_df\n",
        "\n",
        "# path = str(data_dir / 'train' / tgt_cns[0] / pns[0] / 'supplemental' / 'gnss_log.txt')\n",
        "\n",
        "# gnss_section_names = {'Raw', 'UncalAccel', 'UncalGyro', 'UncalMag', 'Fix', 'Status', 'OrientationDeg'}\n",
        "\n",
        "# with open(path) as f_open:\n",
        "#   datalines = f_open.readlines()\n",
        "# datas = {k: [] for k in gnss_section_names}\n",
        "# gnss_map = {k: [] for k in gnss_section_names}\n",
        "# for dataline in datalines:\n",
        "#   if dataline.rstrip():\n",
        "#     is_header = dataline.startswith('#')\n",
        "#     dataline = dataline.strip('#').strip().split(',')\n",
        "#     # skip over notes, version numbers, etc\n",
        "#     if is_header and dataline[0] in gnss_section_names:\n",
        "#         gnss_map[dataline[0]] = dataline[1:]\n",
        "#     elif not is_header:\n",
        "#         datas[dataline[0]].append(dataline[1:])\n"
      ],
      "metadata": {
        "id": "e2fHMcbE-kFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gnss_log_to_dataframes(path):\n",
        "    '''Load GNSS Log'''\n",
        "    print('Loading ' + path, flush = True)\n",
        "    gnss_section_names = {'Raw', 'UncalAccel', 'UncalGyro', 'UncalMag', 'Fix', 'Status', 'OrientationDeg'}\n",
        "    with open(path) as f_open:\n",
        "        datalines = f_open.readlines()\n",
        "\n",
        "    datas = {k: [] for k in gnss_section_names}\n",
        "    gnss_map = {k: [] for k in gnss_section_names}\n",
        "    for dataline in datalines:\n",
        "      if dataline.rstrip():\n",
        "        is_header = dataline.startswith('#')\n",
        "        dataline = dataline.strip('#').strip().split(',')\n",
        "        # skip over notes, version numbers, etc\n",
        "        if is_header and dataline[0] in gnss_section_names:\n",
        "            gnss_map[dataline[0]] = dataline[1:]\n",
        "        elif not is_header:\n",
        "            datas[dataline[0]].append(dataline[1:])\n",
        "\n",
        "    results = dict()\n",
        "    for k, v in datas.items():\n",
        "        results[k] = pd.DataFrame(v, columns=gnss_map[k])\n",
        "    # pandas doesn't properly infer types from these lists by default\n",
        "    for k, df in results.items():\n",
        "        for col in df.columns:\n",
        "            if col == 'CodeType':\n",
        "                continue\n",
        "            results[k][col] = pd.to_numeric(results[k][col])\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:02:46.258084Z",
          "iopub.execute_input": "2021-07-03T09:02:46.258463Z",
          "iopub.status.idle": "2021-07-03T09:02:46.268279Z",
          "shell.execute_reply.started": "2021-07-03T09:02:46.258411Z",
          "shell.execute_reply": "2021-07-03T09:02:46.267312Z"
        },
        "trusted": true,
        "id": "5fMEjMTd0o7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def UTC2GpsEpoch(df):\n",
        "    '''UTC to GpsEpoch\n",
        "    \n",
        "    utcTimeMillis         : UTC epoch (1970/1/1)\n",
        "    millisSinceGpsEpoch   : GPS epoch(1980/1/6 midnight 12:00 UTC)\n",
        "    \n",
        "    Ref: https://www.kaggle.com/c/google-smartphone-decimeter-challenge/discussion/239187\n",
        "    '''\n",
        "    dt_offset = pd.to_datetime('1980-01-06 00:00:00') \n",
        "    dt_offset_in_ms = int(dt_offset.value / 1e6)\n",
        "    df['millisSinceGpsEpoch'] = df['utcTimeMillis'] - dt_offset_in_ms + 18000\n",
        "    return df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:03:32.156022Z",
          "iopub.execute_input": "2021-07-03T09:03:32.156441Z",
          "iopub.status.idle": "2021-07-03T09:03:32.161209Z",
          "shell.execute_reply.started": "2021-07-03T09:03:32.156383Z",
          "shell.execute_reply": "2021-07-03T09:03:32.160334Z"
        },
        "trusted": true,
        "id": "ERlr1Mvx0o70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnss_df = gnss_log_to_dataframes(str(data_dir / 'train' / tgt_cns[0] / pns[0] / 'supplemental' / 'gnss_log.txt'))\n",
        "\n",
        "print('sub-dataset shape：')\n",
        "print('Raw:', gnss_df['Raw'].shape)\n",
        "print('Status:', gnss_df['Status'].shape)\n",
        "print('UncalAccel:', gnss_df['UncalAccel'].shape)\n",
        "print('UncalGyro:', gnss_df['UncalGyro'].shape)\n",
        "print('UncalMag:', gnss_df['UncalMag'].shape)\n",
        "print('OrientationDeg:', gnss_df['OrientationDeg'].shape)\n",
        "print('Fix:', gnss_df['Fix'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNUZR41iHYtB",
        "outputId": "b37da461-10e5-4a37-887b-e7fb5df9e266"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading /content/drive/MyDrive/Google_decimeter/smartphone-decimeter-2022/train/2021-12-28-US-MTV-1/SamsungGalaxyS20Ultra/supplemental/gnss_log.txt\n",
            "sub-dataset shape：\n",
            "Raw: (62648, 36)\n",
            "Status: (0, 13)\n",
            "UncalAccel: (99351, 8)\n",
            "UncalGyro: (80754, 8)\n",
            "UncalMag: (161508, 8)\n",
            "OrientationDeg: (0, 5)\n",
            "Fix: (0, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'train'\n",
        "cname = tgt_cns[0]\n",
        "pname = pns[0]"
      ],
      "metadata": {
        "id": "Z4c47EghIDhm"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imu_df = pd.merge_asof(gnss_df['UncalAccel'].sort_values('utcTimeMillis'),\n",
        "                        gnss_df['UncalGyro'].drop('elapsedRealtimeNanos', axis=1).sort_values('utcTimeMillis'),\n",
        "                        on = 'utcTimeMillis',\n",
        "                        direction='nearest')\n",
        "# (accel + gyro) + mag\n",
        "imu_df = pd.merge_asof(imu_df.sort_values('utcTimeMillis'),\n",
        "                        gnss_df['UncalMag'].drop('elapsedRealtimeNanos', axis=1).sort_values('utcTimeMillis'),\n",
        "                        on = 'utcTimeMillis',\n",
        "                        direction='nearest')\n",
        "# ((accel + gyro) + mag) + OrientationDeg\n",
        "imu_df = pd.merge_asof(imu_df.sort_values('utcTimeMillis'),\n",
        "                        gnss_df['OrientationDeg'].drop('elapsedRealtimeNanos', axis=1).sort_values('utcTimeMillis'),\n",
        "                        on = 'utcTimeMillis',\n",
        "                        direction='nearest')\n",
        "\n",
        "imu_df = imu_df.rename(columns = {'utcTimeMillis': 'UnixTimeMillis'})\n",
        "\n",
        "if dataset_name == 'train':\n",
        "    # read GT dataset\n",
        "    gt_path = data_dir / dataset_name / cname / pname / 'ground_truth.csv'\n",
        "    #might need to add cols of course and phone before unixtime millis\n",
        "    gt_df = pd.read_csv(gt_path, usecols = ['UnixTimeMillis', 'LatitudeDegrees', 'LongitudeDegrees'])\n",
        "\n",
        "\n",
        "    # print GT time\n",
        "    # tmp_datetime = pd.to_datetime(gt_df['millisSinceGpsEpoch'] + dt_offset_in_ms, unit='ms')\n",
        "    # print(f\"gt_df time scope: {tmp_datetime.min()} - {tmp_datetime.max()}\")\n",
        "\n",
        "    # merge GT dataset\n",
        "    imu_df = pd.merge_asof(gt_df.sort_values('UnixTimeMillis'),\n",
        "                            imu_df.drop(['elapsedRealtimeNanos'], axis=1).sort_values('UnixTimeMillis'),\n",
        "                            on = 'UnixTimeMillis',\n",
        "                            direction='nearest')\n",
        "elif dataset_name == 'test':\n",
        "    # merge smaple_df\n",
        "    imu_df = pd.merge_asof(sample_df.sort_values('UnixTimeMillis'),\n",
        "                        imu_df.drop(['elapsedRealtimeNanos'], axis=1).sort_values('UnixTimeMillis'),\n",
        "                        on = 'UnixTimeMillis',\n",
        "                        direction='nearest')\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "ZCHHkTVhHzMC"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "9LdakaMKIO0D",
        "outputId": "6d23c884-3b8d-4e36-e771-a2c8411bff73"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   LatitudeDegrees  LongitudeDegrees  UnixTimeMillis  UncalAccelXMps2  \\\n",
              "0         37.41603        -122.08094   1640722632000        -0.153229   \n",
              "1         37.41603        -122.08094   1640722633000        -0.134075   \n",
              "2         37.41603        -122.08094   1640722634000        -0.155623   \n",
              "3         37.41603        -122.08094   1640722635000        -0.148441   \n",
              "4         37.41603        -122.08094   1640722636000        -0.093374   \n",
              "\n",
              "   UncalAccelYMps2  UncalAccelZMps2  BiasXMps2  BiasYMps2  BiasZMps2  \\\n",
              "0         9.665691        -2.063802        0.0        0.0        0.0   \n",
              "1         9.620202        -2.056619        0.0        0.0        0.0   \n",
              "2         9.648932        -2.123657        0.0        0.0        0.0   \n",
              "3         9.601048        -2.068590        0.0        0.0        0.0   \n",
              "4         9.567530        -2.111686        0.0        0.0        0.0   \n",
              "\n",
              "   UncalGyroXRadPerSec  ...  DriftZRadPerSec  UncalMagXMicroT  \\\n",
              "0             0.000153  ...              0.0        81.659996   \n",
              "1            -0.004734  ...              0.0        82.080000   \n",
              "2            -0.001069  ...              0.0        81.780000   \n",
              "3            -0.005956  ...              0.0        81.420000   \n",
              "4            -0.002291  ...              0.0        81.840000   \n",
              "\n",
              "   UncalMagYMicroT  UncalMagZMicroT  BiasXMicroT  BiasYMicroT  BiasZMicroT  \\\n",
              "0       -57.780000       -32.100000         51.0       -14.88       -56.76   \n",
              "1       -57.420000       -32.219997         51.0       -14.88       -56.76   \n",
              "2       -57.719997       -32.040000         51.0       -14.88       -56.76   \n",
              "3       -57.660000       -31.920000         51.0       -14.88       -56.76   \n",
              "4       -57.600000       -32.460000         51.0       -14.88       -56.76   \n",
              "\n",
              "   yawDeg  rollDeg  pitchDeg  \n",
              "0     NaN      NaN       NaN  \n",
              "1     NaN      NaN       NaN  \n",
              "2     NaN      NaN       NaN  \n",
              "3     NaN      NaN       NaN  \n",
              "4     NaN      NaN       NaN  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddbb4150-0390-4bfc-8b3f-a1294ed06fe6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LatitudeDegrees</th>\n",
              "      <th>LongitudeDegrees</th>\n",
              "      <th>UnixTimeMillis</th>\n",
              "      <th>UncalAccelXMps2</th>\n",
              "      <th>UncalAccelYMps2</th>\n",
              "      <th>UncalAccelZMps2</th>\n",
              "      <th>BiasXMps2</th>\n",
              "      <th>BiasYMps2</th>\n",
              "      <th>BiasZMps2</th>\n",
              "      <th>UncalGyroXRadPerSec</th>\n",
              "      <th>...</th>\n",
              "      <th>DriftZRadPerSec</th>\n",
              "      <th>UncalMagXMicroT</th>\n",
              "      <th>UncalMagYMicroT</th>\n",
              "      <th>UncalMagZMicroT</th>\n",
              "      <th>BiasXMicroT</th>\n",
              "      <th>BiasYMicroT</th>\n",
              "      <th>BiasZMicroT</th>\n",
              "      <th>yawDeg</th>\n",
              "      <th>rollDeg</th>\n",
              "      <th>pitchDeg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37.41603</td>\n",
              "      <td>-122.08094</td>\n",
              "      <td>1640722632000</td>\n",
              "      <td>-0.153229</td>\n",
              "      <td>9.665691</td>\n",
              "      <td>-2.063802</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000153</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.659996</td>\n",
              "      <td>-57.780000</td>\n",
              "      <td>-32.100000</td>\n",
              "      <td>51.0</td>\n",
              "      <td>-14.88</td>\n",
              "      <td>-56.76</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37.41603</td>\n",
              "      <td>-122.08094</td>\n",
              "      <td>1640722633000</td>\n",
              "      <td>-0.134075</td>\n",
              "      <td>9.620202</td>\n",
              "      <td>-2.056619</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.004734</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.080000</td>\n",
              "      <td>-57.420000</td>\n",
              "      <td>-32.219997</td>\n",
              "      <td>51.0</td>\n",
              "      <td>-14.88</td>\n",
              "      <td>-56.76</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37.41603</td>\n",
              "      <td>-122.08094</td>\n",
              "      <td>1640722634000</td>\n",
              "      <td>-0.155623</td>\n",
              "      <td>9.648932</td>\n",
              "      <td>-2.123657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.001069</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.780000</td>\n",
              "      <td>-57.719997</td>\n",
              "      <td>-32.040000</td>\n",
              "      <td>51.0</td>\n",
              "      <td>-14.88</td>\n",
              "      <td>-56.76</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37.41603</td>\n",
              "      <td>-122.08094</td>\n",
              "      <td>1640722635000</td>\n",
              "      <td>-0.148441</td>\n",
              "      <td>9.601048</td>\n",
              "      <td>-2.068590</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.005956</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.420000</td>\n",
              "      <td>-57.660000</td>\n",
              "      <td>-31.920000</td>\n",
              "      <td>51.0</td>\n",
              "      <td>-14.88</td>\n",
              "      <td>-56.76</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37.41603</td>\n",
              "      <td>-122.08094</td>\n",
              "      <td>1640722636000</td>\n",
              "      <td>-0.093374</td>\n",
              "      <td>9.567530</td>\n",
              "      <td>-2.111686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.002291</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.840000</td>\n",
              "      <td>-57.600000</td>\n",
              "      <td>-32.460000</td>\n",
              "      <td>51.0</td>\n",
              "      <td>-14.88</td>\n",
              "      <td>-56.76</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddbb4150-0390-4bfc-8b3f-a1294ed06fe6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddbb4150-0390-4bfc-8b3f-a1294ed06fe6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddbb4150-0390-4bfc-8b3f-a1294ed06fe6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_imu_data(data_dir, dataset_name, cname, pname, bl_df):\n",
        "    '''Prepare IMU Dataset (For Train: IMU+GT+BL; For Test: IMU+BL)\n",
        "    Input：\n",
        "        1. data_dir: data_dir\n",
        "        2. dataset_name: dataset name（'train'/'test'）\n",
        "        3. cname: CollectionName\n",
        "        4. pname: phoneName\n",
        "        5. bl_df: baseline's dataframe\n",
        "    Output：df_all\n",
        "    '''\n",
        "    # load GNSS log\n",
        "    gnss_df = gnss_log_to_dataframes(str(data_dir / dataset_name / cname / pname / 'supplemental' / 'gnss_log.txt'))\n",
        "    print('sub-dataset shape：')\n",
        "    print('Raw:', gnss_df['Raw'].shape)\n",
        "    print('Status:', gnss_df['Status'].shape)\n",
        "    print('UncalAccel:', gnss_df['UncalAccel'].shape)\n",
        "    print('UncalGyro:', gnss_df['UncalGyro'].shape)\n",
        "    print('UncalMag:', gnss_df['UncalMag'].shape)\n",
        "    print('OrientationDeg:', gnss_df['OrientationDeg'].shape)\n",
        "    print('Fix:', gnss_df['Fix'].shape)\n",
        "\n",
        "    # merge sub-datasets\n",
        "    # accel + gyro\n",
        "    imu_df = pd.merge_asof(gnss_df['UncalAccel'].sort_values('utcTimeMillis'),\n",
        "                           gnss_df['UncalGyro'].drop('elapsedRealtimeNanos', axis=1).sort_values('utcTimeMillis'),\n",
        "                           on = 'utcTimeMillis',\n",
        "                           direction='nearest')\n",
        "    # (accel + gyro) + mag\n",
        "    imu_df = pd.merge_asof(imu_df.sort_values('utcTimeMillis'),\n",
        "                           gnss_df['UncalMag'].drop('elapsedRealtimeNanos', axis=1).sort_values('utcTimeMillis'),\n",
        "                           on = 'utcTimeMillis',\n",
        "                           direction='nearest')\n",
        "    # ((accel + gyro) + mag) + OrientationDeg\n",
        "    imu_df = pd.merge_asof(imu_df.sort_values('utcTimeMillis'),\n",
        "                           gnss_df['OrientationDeg'].drop('elapsedRealtimeNanos', axis=1).sort_values('utcTimeMillis'),\n",
        "                           on = 'utcTimeMillis',\n",
        "                           direction='nearest')\n",
        "    \n",
        "    imu_df = imu_df.rename(columns = {'utcTimeMillis': 'UnixTimeMillis'})\n",
        "    \n",
        "    # UTC->GpsEpoch\n",
        "    # imu_df = UTC2GpsEpoch(imu_df)\n",
        "    # I think I can just leave it in UTC cuz everything is in that.\n",
        "\n",
        "    # print IMU time\n",
        "    # dt_offset = pd.to_datetime('1980-01-06 00:00:00')\n",
        "    # dt_offset_in_ms = int(dt_offset.value / 1e6)\n",
        "    # tmp_datetime = pd.to_datetime(imu_df['millisSinceGpsEpoch'] + dt_offset_in_ms, unit='ms')\n",
        "    # print(f\"imu_df time scope: {tmp_datetime.min()} - {tmp_datetime.max()}\")\n",
        "\n",
        "\n",
        "    if dataset_name == 'train':\n",
        "        # read GT dataset\n",
        "        gt_path = data_dir / dataset_name / cname / pname / 'ground_truth.csv'\n",
        "        #might need to add cols of course and phone before unixtime millis\n",
        "        gt_df = pd.read_csv(gt_path, usecols = ['UnixTimeMillis', 'LatitudeDegrees', 'LongitudeDegrees'])\n",
        "\n",
        "\n",
        "        # print GT time\n",
        "        # tmp_datetime = pd.to_datetime(gt_df['millisSinceGpsEpoch'] + dt_offset_in_ms, unit='ms')\n",
        "        # print(f\"gt_df time scope: {tmp_datetime.min()} - {tmp_datetime.max()}\")\n",
        "\n",
        "        # merge GT dataset\n",
        "        imu_df = pd.merge_asof(gt_df.sort_values('UnixTimeMillis'),\n",
        "                               imu_df.drop(['elapsedRealtimeNanos'], axis=1).sort_values('UnixTimeMillis'),\n",
        "                               on = 'UnixTimeMillis',\n",
        "                               direction='nearest')\n",
        "    elif dataset_name == 'test':\n",
        "        # merge smaple_df\n",
        "        imu_df = pd.merge_asof(sample_df.sort_values('UnixTimeMillis'),\n",
        "                           imu_df.drop(['elapsedRealtimeNanos'], axis=1).sort_values('UnixTimeMillis'),\n",
        "                           on = 'UnixTimeMillis',\n",
        "                           direction='nearest')\n",
        "\n",
        "    # OrientationDeg -> Rotation Vector\n",
        "    rxs = []\n",
        "    rys = []\n",
        "    rzs = []\n",
        "    for i in range(len(imu_df)):\n",
        "        y_delta = imu_df['rollDeg'].iloc[i]\n",
        "        z_delta = imu_df['yawDeg'].iloc[i]\n",
        "        x_delta = imu_df['pitchDeg'].iloc[i]\n",
        "        rx, ry, rz = an2v(y_delta, z_delta, x_delta)\n",
        "        rxs.append(rx)\n",
        "        rys.append(ry)\n",
        "        rzs.append(rz)\n",
        "\n",
        "    imu_df['ahrsX'] = rxs\n",
        "    imu_df['ahrsY'] = rys\n",
        "    imu_df['ahrsZ'] = rzs\n",
        "\n",
        "    # calibrate sensors' reading\n",
        "    for axis in ['X', 'Y', 'Z']:\n",
        "        imu_df['Accel{}Mps2'.format(axis)] = imu_df['UncalAccel{}Mps2'.format(axis)] - imu_df['Bias{}Mps2'.format(axis)]\n",
        "        imu_df['Gyro{}RadPerSec'.format(axis)] = imu_df['UncalGyro{}RadPerSec'.format(axis)] - imu_df['Drift{}RadPerSec'.format(axis)]\n",
        "        imu_df['Mag{}MicroT'.format(axis)] = imu_df['UncalMag{}MicroT'.format(axis)] - imu_df['Bias{}MicroT'.format(axis)]\n",
        "\n",
        "        # clearn bias features\n",
        "        imu_df.drop(['Bias{}Mps2'.format(axis), 'Drift{}RadPerSec'.format(axis), 'Bias{}MicroT'.format(axis)], axis = 1, inplace = True) \n",
        "#FLAG... I don't have latdeg for bl i have xyz. see if later on its turned to xyz.\n",
        "    bl_df.rename(columns = {'utcTimeMillis': 'UnixTimeMillis'})\n",
        "    if dataset_name == 'train':\n",
        "        # merge Baseline dataset：imu_df + bl_df = (GT + IMU) + Baseline\n",
        "        df_all = pd.merge(imu_df.rename(columns={'LatitudeDegree':'latDeg_gt', 'LongitudeDegree':'lngDeg_gt'}),\n",
        "                      bl_df,\n",
        "                      on = ['collectionName', 'phoneName', 'UnixTimeMillis'])\n",
        "    elif dataset_name == 'test':\n",
        "        df_all = pd.merge(imu_df,\n",
        "              bl_df[(bl_df['collectionName']==cname) & (bl_df['phoneName']==pname)],\n",
        "              on = ['UnixTimeMillis'])\n",
        "        # df_all.drop(['phone'], axis=1, inplace=True)\n",
        "        \n",
        "    return df_all"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:19:03.200949Z",
          "iopub.execute_input": "2021-07-03T09:19:03.201315Z",
          "iopub.status.idle": "2021-07-03T09:19:03.241204Z",
          "shell.execute_reply.started": "2021-07-03T09:19:03.201284Z",
          "shell.execute_reply": "2021-07-03T09:19:03.240111Z"
        },
        "trusted": true,
        "id": "K2CFkldt0o70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all()"
      ],
      "metadata": {
        "id": "i3ZUshPzEgCr",
        "outputId": "f9b2e8d8-a488-4b4b-cfc8-db7c778a0494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-216-6bcda17f63bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_all' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def WGS84_to_ECEF(lat, lon, alt):\n",
        "    # convert to radians\n",
        "    rad_lat = lat * (np.pi / 180.0)\n",
        "    rad_lon = lon * (np.pi / 180.0)\n",
        "    a    = 6378137.0\n",
        "    # f is the flattening factor\n",
        "    finv = 298.257223563\n",
        "    f = 1 / finv   \n",
        "    # e is the eccentricity\n",
        "    e2 = 1 - (1 - f) * (1 - f)    \n",
        "    # N is the radius of curvature in the prime vertical\n",
        "    N = a / np.sqrt(1 - e2 * np.sin(rad_lat) * np.sin(rad_lat))\n",
        "    x = (N + alt) * np.cos(rad_lat) * np.cos(rad_lon)\n",
        "    y = (N + alt) * np.cos(rad_lat) * np.sin(rad_lon)\n",
        "    z = (N * (1 - e2) + alt)        * np.sin(rad_lat)\n",
        "    return x, y, z\n",
        "\n",
        "transformer = pyproj.Transformer.from_crs(\n",
        "    {\"proj\":'geocent', \"ellps\":'WGS84', \"datum\":'WGS84'},\n",
        "    {\"proj\":'latlong', \"ellps\":'WGS84', \"datum\":'WGS84'},)\n",
        "def ECEF_to_WGS84(x,y,z):\n",
        "    lon, lat, alt = transformer.transform(x,y,z,radians=False)\n",
        "    return lon, lat, alt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:07:42.761232Z",
          "iopub.execute_input": "2021-07-03T09:07:42.761745Z",
          "iopub.status.idle": "2021-07-03T09:07:42.83369Z",
          "shell.execute_reply.started": "2021-07-03T09:07:42.761711Z",
          "shell.execute_reply": "2021-07-03T09:07:42.832643Z"
        },
        "trusted": true,
        "id": "G_4-cuC80o71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_xyz(df_all, dataset_name):\n",
        "    # baseline: lat/lngDeg -> x/y/z\n",
        "    #FLAG might want to just delete this first line here\n",
        "    df_all['Xbl'], df_all['Ybl'], df_all['Zbl'] = zip(*df_all.apply(lambda x: WGS84_to_ECEF(x.latDeg_bl, x.lngDeg_bl, x.heightAboveWgs84EllipsoidM), axis=1))\n",
        "    \n",
        "    if dataset_name == 'train':\n",
        "        # gt: lat/lngDeg -> x/y/z\n",
        "        df_all['Xgt'], df_all['Ygt'], df_all['Zgt'] = zip(*df_all.apply(lambda x: WGS84_to_ECEF(x.latDeg_gt, x.lngDeg_gt, x.heightAboveWgs84EllipsoidM), axis=1))\n",
        "        # copy lat/lngDeg\n",
        "        lat_lng_df = df_all[['latDeg_gt','lngDeg_gt', 'latDeg_bl', 'lngDeg_bl']]\n",
        "        #FLAG will need to modify here. Do I need to put baseline into lat long?\n",
        "        df_all.drop(['latDeg_gt','lngDeg_gt', 'latDeg_bl', 'lngDeg_bl'], axis = 1, inplace = True)\n",
        "    elif dataset_name == 'test':\n",
        "        # copy lat/lngDeg\n",
        "        lat_lng_df = df_all[['latDeg_bl', 'lngDeg_bl']]\n",
        "        #FLAG here too\n",
        "        df_all.drop(['latDeg_bl', 'lngDeg_bl', 'latDeg','lngDeg',], axis = 1, inplace = True)     \n",
        "        \n",
        "    return lat_lng_df, df_all"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:08:34.380405Z",
          "iopub.execute_input": "2021-07-03T09:08:34.381036Z",
          "iopub.status.idle": "2021-07-03T09:08:34.390474Z",
          "shell.execute_reply.started": "2021-07-03T09:08:34.380989Z",
          "shell.execute_reply": "2021-07-03T09:08:34.38945Z"
        },
        "trusted": true,
        "id": "bq4RFa-N0o72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_df_train(df_all_train, window_size):\n",
        "    '''prepare training dataset with all aixses'''\n",
        "    tgt_df = df_all_train.copy()\n",
        "    total_len = len(tgt_df) \n",
        "    moving_times = total_len - window_size \n",
        "    \n",
        "    tgt_df.rename(columns = {'yawDeg':'yawZDeg', 'rollDeg':'rollYDeg', 'pitchDeg':'pitchXDeg'}, inplace = True)\n",
        "\n",
        "    feature_cols = [f for f in list(tgt_df) if f not in ['Xgt', 'Ygt', 'Zgt']]\n",
        "\n",
        "    # Historical Feature names\n",
        "    hist_feats = []\n",
        "    for time_flag in range(1, window_size + 1):\n",
        "        for fn in feature_cols:\n",
        "            hist_feats.append(fn + '_' + str(time_flag))\n",
        "\n",
        "    # Window Sliding\n",
        "    # t1 t2 t3 t4 t5 -> t6\n",
        "    # t2 t3 t4 t5 t6 -> t7\n",
        "\n",
        "    # Add historical data \n",
        "    df_train = pd.DataFrame()\n",
        "    features = []\n",
        "    xs = []\n",
        "    ys = []\n",
        "    zs = []\n",
        "\n",
        "    for start_idx in range(moving_times):\n",
        "        feature_list = list()\n",
        "        x_list = list()\n",
        "        y_list = list()\n",
        "        z_list = list()\n",
        "\n",
        "        for window_idx in range(window_size):\n",
        "            feature_list.extend(tgt_df[feature_cols].iloc[start_idx + window_idx,:].to_list())\n",
        "        x_list.append(tgt_df['Xgt'].iloc[start_idx + window_size])\n",
        "        y_list.append(tgt_df['Ygt'].iloc[start_idx + window_size])\n",
        "        z_list.append(tgt_df['Zgt'].iloc[start_idx + window_size])\n",
        "\n",
        "        features.append(feature_list)\n",
        "        xs.extend(x_list)\n",
        "        ys.extend(y_list)\n",
        "        zs.extend(z_list)\n",
        "\n",
        "    df_train = pd.DataFrame(features, columns = hist_feats)\n",
        "    df_train['Xgt'] = xs\n",
        "    df_train['Ygt'] = ys\n",
        "    df_train['Zgt'] = zs\n",
        "    \n",
        "    # clean single-value feature: collectionName_[1-5]\\phoneName_[1-5]\n",
        "    tmp_feats = []\n",
        "    for fn in list(df_train):\n",
        "        if (fn.startswith('collectionName_') == False) and (fn.startswith('phoneName_') == False):\n",
        "            tmp_feats.append(fn)\n",
        "    df_train = df_train[tmp_feats]\n",
        "\n",
        "    # clean time feature\n",
        "    tmp_drop_feats = []\n",
        "    for f in list(df_train):\n",
        "        if (f.startswith('millisSinceGpsEpoch') == True) or (f.startswith('timeSinceFirstFixSeconds') == True) or (f.startswith('utcTimeMillis') == True):\n",
        "            tmp_drop_feats.append(f)\n",
        "    df_train.drop(tmp_drop_feats, axis = 1, inplace = True)\n",
        "    \n",
        "    return df_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:10:39.073913Z",
          "iopub.execute_input": "2021-07-03T09:10:39.074283Z",
          "iopub.status.idle": "2021-07-03T09:10:39.092284Z",
          "shell.execute_reply.started": "2021-07-03T09:10:39.074253Z",
          "shell.execute_reply": "2021-07-03T09:10:39.090301Z"
        },
        "trusted": true,
        "id": "xHN_cVUE0o72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_df_test(df_all_test, window_size):\n",
        "    '''prepare testing dataset with all aixses'''\n",
        "    tgt_df = df_all_test.copy()\n",
        "    total_len = len(tgt_df) \n",
        "    moving_times = total_len - window_size \n",
        "    \n",
        "    tgt_df.rename(columns = {'yawDeg':'yawZDeg', 'rollDeg':'rollYDeg', 'pitchDeg':'pitchXDeg'}, inplace = True)\n",
        "\n",
        "    feature_cols = [f for f in list(tgt_df) if f not in ['Xgt', 'Ygt', 'Zgt']] \n",
        "    \n",
        "    hist_feats = []\n",
        "    for time_flag in range(1, window_size + 1):\n",
        "        for fn in feature_cols:\n",
        "            hist_feats.append(fn + '_' + str(time_flag))\n",
        "\n",
        "    # t1 t2 t3 t4 t5 -> t6\n",
        "    # t2 t3 t4 t5 t6 -> t7\n",
        "    df_test = pd.DataFrame()\n",
        "    features = []\n",
        "\n",
        "    for start_idx in range(moving_times):\n",
        "        feature_list = list()\n",
        "\n",
        "        for window_idx in range(window_size):\n",
        "            feature_list.extend(tgt_df[feature_cols].iloc[start_idx + window_idx,:].to_list())\n",
        "        features.append(feature_list)\n",
        "\n",
        "    df_test = pd.DataFrame(features, columns = hist_feats)\n",
        "\n",
        "    tmp_feats = []\n",
        "    for fn in list(df_test):\n",
        "        if (fn.startswith('collectionName_') == False) and (fn.startswith('phoneName_') == False):\n",
        "            tmp_feats.append(fn)\n",
        "    df_test = df_test[tmp_feats]\n",
        "\n",
        "    tmp_drop_feats = []\n",
        "    for f in list(df_test):\n",
        "        if (f.startswith('millisSinceGpsEpoch') == True) or (f.startswith('timeSinceFirstFixSeconds') == True) or (f.startswith('utcTimeMillis') == True) or (f.startswith('elapsedRealtimeNanos') == True):\n",
        "            tmp_drop_feats.append(f)\n",
        "    df_test.drop(tmp_drop_feats, axis = 1, inplace = True)\n",
        "    \n",
        "    return df_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:11:15.153558Z",
          "iopub.execute_input": "2021-07-03T09:11:15.154053Z",
          "iopub.status.idle": "2021-07-03T09:11:15.165799Z",
          "shell.execute_reply.started": "2021-07-03T09:11:15.15402Z",
          "shell.execute_reply": "2021-07-03T09:11:15.16459Z"
        },
        "trusted": true,
        "id": "1Xq3m0mJ0o72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_other_axis_feats(df_all, tgt_axis):\n",
        "    '''unrelated-aixs features and uncalibrated features'''\n",
        "    # Clean unrelated-aixs features\n",
        "    all_imu_feats = ['UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2',\n",
        "                     'UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec',\n",
        "                     'UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT',\n",
        "                     'ahrsX', 'ahrsY', 'ahrsZ',\n",
        "                     'AccelXMps2', 'AccelYMps2', 'AccelZMps2',\n",
        "                     'GyroXRadPerSec', 'GyroZRadPerSec', 'GyroYRadPerSec',\n",
        "                     'MagXMicroT', 'MagYMicroT', 'MagZMicroT',\n",
        "                     'yawZDeg', 'rollYDeg', 'pitchXDeg',\n",
        "                     'Xbl', 'Ybl', 'Zbl']\n",
        "    tgt_imu_feats = []\n",
        "    for axis in ['X', 'Y', 'Z']:\n",
        "        if axis != tgt_axis:\n",
        "            for f in all_imu_feats:\n",
        "                if f.find(axis) >= 0:\n",
        "                    tgt_imu_feats.append(f)\n",
        "            \n",
        "    tmp_drop_feats = []\n",
        "    for f in list(df_all):\n",
        "        if f.split('_')[0] in tgt_imu_feats:\n",
        "            tmp_drop_feats.append(f)\n",
        "\n",
        "    tgt_df = df_all.drop(tmp_drop_feats, axis = 1)\n",
        "    \n",
        "    # Clean uncalibrated features\n",
        "    uncal_feats = [f for f in list(tgt_df) if f.startswith('Uncal') == True]\n",
        "    tgt_df = tgt_df.drop(uncal_feats, axis = 1)\n",
        "    \n",
        "    return tgt_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:12:32.753679Z",
          "iopub.execute_input": "2021-07-03T09:12:32.754264Z",
          "iopub.status.idle": "2021-07-03T09:12:32.762735Z",
          "shell.execute_reply.started": "2021-07-03T09:12:32.754229Z",
          "shell.execute_reply": "2021-07-03T09:12:32.761749Z"
        },
        "trusted": true,
        "id": "ngFAIMb50o73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_stat_feats(data, tgt_axis):\n",
        "    for f in ['yawZDeg', 'rollYDeg', 'pitchXDeg']:\n",
        "        if f.find(tgt_axis) >= 0:\n",
        "            ori_feat = f\n",
        "            break\n",
        "            \n",
        "    cont_feats = ['heightAboveWgs84EllipsoidM', 'ahrs{}'.format(tgt_axis),\n",
        "           'Accel{}Mps2'.format(tgt_axis), 'Gyro{}RadPerSec'.format(tgt_axis), 'Mag{}MicroT'.format(tgt_axis),\n",
        "            '{}bl'.format(tgt_axis)] + [ori_feat]\n",
        "    \n",
        "    for f in cont_feats:\n",
        "        data[f + '_' + str(window_size) + '_mean'] = data[[f + f'_{i}' for i in range(1,window_size)]].mean(axis=1)\n",
        "        data[f + '_' + str(window_size) + '_std'] = data[[f + f'_{i}' for i in range(1,window_size)]].std(axis=1)\n",
        "        data[f + '_' + str(window_size) + '_max'] = data[[f + f'_{i}' for i in range(1,window_size)]].max(axis=1)\n",
        "        data[f + '_' + str(window_size) + '_min'] = data[[f + f'_{i}' for i in range(1,window_size)]].min(axis=1)\n",
        "        data[f + '_' + str(window_size) + '_median'] = data[[f + f'_{i}' for i in range(1,window_size)]].median(axis=1)\n",
        "    return data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:48:34.975766Z",
          "iopub.execute_input": "2021-07-03T09:48:34.976178Z",
          "iopub.status.idle": "2021-07-03T09:48:34.988282Z",
          "shell.execute_reply.started": "2021-07-03T09:48:34.976143Z",
          "shell.execute_reply": "2021-07-03T09:48:34.986628Z"
        },
        "trusted": true,
        "id": "a-a-xma20o73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Modeling\n",
        "Note: I only use the given axis features for predict the target axis location.<br>\n",
        "For example, use features contains x-axis to predict the next x location.<br>\n",
        "More, I used LGBM here."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:14:32.286714Z",
          "iopub.execute_input": "2021-07-03T09:14:32.287331Z",
          "iopub.status.idle": "2021-07-03T09:14:32.293464Z",
          "shell.execute_reply.started": "2021-07-03T09:14:32.287291Z",
          "shell.execute_reply": "2021-07-03T09:14:32.292014Z"
        },
        "id": "eYtZDtCU0o73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM\n",
        "params = {\n",
        "    'metric':'mse',\n",
        "    'objective':'regression',\n",
        "    'seed':2021,\n",
        "    'boosting_type':'gbdt',\n",
        "    'early_stopping_rounds':10,\n",
        "    'subsample':0.7,\n",
        "    'feature_fraction':0.7,\n",
        "    'bagging_fraction': 0.7,\n",
        "    'reg_lambda': 10\n",
        "}\n",
        "window_size = 30\n",
        "verbose_flag = True\n",
        "folds = 5"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:34:28.859105Z",
          "iopub.execute_input": "2021-07-03T09:34:28.85964Z",
          "iopub.status.idle": "2021-07-03T09:34:28.866036Z",
          "shell.execute_reply.started": "2021-07-03T09:34:28.859592Z",
          "shell.execute_reply": "2021-07-03T09:34:28.864628Z"
        },
        "trusted": true,
        "id": "lXTStr2k0o74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tgt_cns = [str(x).split('/')[0] for x in training_sets]\n",
        "pns = [str(x).split('/')[1] for x in training_sets]"
      ],
      "metadata": {
        "id": "4nQA3TcF1ffq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: I use SJC's dataset for training \n",
        "# tgt_cns = ['2021-04-22-US-SJC-1', '2021-04-28-US-SJC-1', '2021-04-29-US-SJC-2']\n",
        "cn2pn_df = bl_trn_df[['collectionName', 'phoneName']].drop_duplicates()\n",
        "\n",
        "df_trains = []\n",
        "lat_lng_df_trains = []\n",
        "for tgt_cn, tgt_pn in zip(tgt_cns, pns):\n",
        "  print('Prepare Training Dataset：', tgt_cn + '_' + tgt_pn)  \n",
        "  df_all_train = prepare_imu_data(data_dir, 'train', tgt_cn, tgt_pn, bl_trn_df)\n",
        "#   lat_lng_df_train, df_all_train = get_xyz(df_all_train, 'train')\n",
        "#   df_train = prepare_df_train(df_all_train,  window_size) # 所有轴的数据\n",
        "#   df_trains.append(df_train)\n",
        "#   lat_lng_df_trains.append(lat_lng_df_train)\n",
        "#   print('_'*20)\n",
        "        \n",
        "# df_train = pd.concat(df_trains, axis = 0)\n",
        "# lat_lng_df_train = pd.concat(lat_lng_df_trains, axis = 0)\n",
        "# print('Final Dataset shape：', df_train.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:19:07.455002Z",
          "iopub.execute_input": "2021-07-03T09:19:07.455368Z",
          "iopub.status.idle": "2021-07-03T09:29:23.787869Z",
          "shell.execute_reply.started": "2021-07-03T09:19:07.455335Z",
          "shell.execute_reply": "2021-07-03T09:29:23.786592Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AupMMBhu0o74",
        "outputId": "4c1cbb5f-5d0b-4ce7-fc9d-54674079dba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepare Training Dataset： 2021-12-28-US-MTV-1_SamsungGalaxyS20Ultra\n",
            "Loading /content/drive/MyDrive/Google_decimeter/smartphone-decimeter-2022/train/2021-12-28-US-MTV-1/SamsungGalaxyS20Ultra/supplemental/gnss_log.txt\n",
            "sub-dataset shape：\n",
            "Raw: (62648, 36)\n",
            "Status: (0, 13)\n",
            "UncalAccel: (99351, 8)\n",
            "UncalGyro: (80754, 8)\n",
            "UncalMag: (161508, 8)\n",
            "OrientationDeg: (0, 5)\n",
            "Fix: (0, 12)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-213-364673ae60ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtgt_cn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_pn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_cns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prepare Training Dataset：'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_cn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtgt_pn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mdf_all_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_imu_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_cn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_pn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbl_trn_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#   lat_lng_df_train, df_all_train = get_xyz(df_all_train, 'train')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#   df_train = prepare_df_train(df_all_train,  window_size) # 所有轴的数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-212-cbccaa54b98c>\u001b[0m in \u001b[0;36mprepare_imu_data\u001b[0;34m(data_dir, dataset_name, cname, pname, bl_df)\u001b[0m\n\u001b[1;32m    103\u001b[0m         df_all = pd.merge(imu_df.rename(columns={'LatitudeDegree':'latDeg_gt', 'LongitudeDegree':'lngDeg_gt'}),\n\u001b[1;32m    104\u001b[0m                       \u001b[0mbl_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                       on = ['collectionName', 'phoneName', 'UnixTimeMillis'])\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         df_all = pd.merge(imu_df,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1107\u001b[0m                         \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1777\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'collectionName'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: I choose one of SJC collection from the test dataset as my test dataset, you can choose what as you like\n",
        "cname_test = '2021-04-29-US-SJC-3'\n",
        "pname_test = 'SamsungS20Ultra'\n",
        "df_all_test = prepare_imu_data(data_dir, 'test', cname_test, pname_test, bl_tst_df)\n",
        "lat_lng_df_test, df_all_test = get_xyz(df_all_test, 'test')\n",
        "df_test = prepare_df_test(df_all_test,  window_size)\n",
        "print('df_test:', df_test.shape)\n",
        "print('df_test.columns:', df_test.columns)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:34:46.467097Z",
          "iopub.execute_input": "2021-07-03T09:34:46.467662Z",
          "iopub.status.idle": "2021-07-03T09:36:24.622097Z",
          "shell.execute_reply.started": "2021-07-03T09:34:46.467612Z",
          "shell.execute_reply": "2021-07-03T09:36:24.620975Z"
        },
        "trusted": true,
        "id": "DRHniLWI0o74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(df_train, df_test, tgt_axis, window_size):\n",
        "    '''For the given axis target to train the model. Also, it has validation and prediciton.'''\n",
        "    df_train = remove_other_axis_feats(df_train, tgt_axis)\n",
        "    df_train = add_stat_feats(df_train, tgt_axis)\n",
        "    df_test = remove_other_axis_feats(df_test, tgt_axis)\n",
        "    df_test = add_stat_feats(df_test, tgt_axis)\n",
        "    \n",
        "    feature_names = [f for f in list(df_train) if f not in ['Xgt', 'Ygt', 'Zgt']]\n",
        "    target = '{}gt'.format(tgt_axis)\n",
        "\n",
        "    kfold = KFold(n_splits=folds, shuffle=True, random_state=params['seed'])\n",
        "\n",
        "    pred_valid = np.zeros((len(df_train),)) \n",
        "    pred_test = np.zeros((len(df_test),)) \n",
        "    scores = []\n",
        "    for fold_id, (trn_idx, val_idx) in enumerate(kfold.split(df_train, df_train[target])):\n",
        "        X_train = df_train.iloc[trn_idx][feature_names]\n",
        "        Y_train = df_train.iloc[trn_idx][target]\n",
        "        X_val = df_train.iloc[val_idx][feature_names]\n",
        "        Y_val = df_train.iloc[val_idx][target]\n",
        "\n",
        "        model = lgb.LGBMRegressor(**params)\n",
        "        lgb_model = model.fit(X_train, \n",
        "                              Y_train,\n",
        "                              eval_names=['train', 'valid'],\n",
        "                              eval_set=[(X_train, Y_train), (X_val, Y_val)],\n",
        "                              verbose=0,\n",
        "                              eval_metric=params['metric'],\n",
        "                              early_stopping_rounds=params['early_stopping_rounds'])\n",
        "\n",
        "        pred_valid[val_idx] = lgb_model.predict(X_val, num_iteration =  lgb_model.best_iteration_)\n",
        "        pred_test += lgb_model.predict(df_test[feature_names], num_iteration =  lgb_model.best_iteration_)\n",
        "\n",
        "        scores.append(lgb_model.best_score_['valid']['l2'])\n",
        "    \n",
        "    pred_test = pred_test /  kfold.n_splits\n",
        "    \n",
        "    if verbose_flag == True:\n",
        "        print(\"Each Fold's MSE：{}, Average MSE：{:.4f}\".format([np.round(v,2) for v in scores], np.mean(scores)))\n",
        "        print(\"-\"*60)\n",
        "    return df_train, df_test, pred_valid, pred_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:48:58.448562Z",
          "iopub.execute_input": "2021-07-03T09:48:58.448997Z",
          "iopub.status.idle": "2021-07-03T09:48:58.462721Z",
          "shell.execute_reply.started": "2021-07-03T09:48:58.448958Z",
          "shell.execute_reply": "2021-07-03T09:48:58.46176Z"
        },
        "trusted": true,
        "id": "e_1HHr4H0o74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_x, df_test_x, pred_valid_x, pred_test_x = training(df_train, df_test, 'X', window_size)\n",
        "df_train_y, df_test_y, pred_valid_y, pred_test_y = training(df_train, df_test, 'Y', window_size)\n",
        "df_train_z, df_test_z, pred_valid_z, pred_test_z = training(df_train, df_test, 'Z', window_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:48:59.051261Z",
          "iopub.execute_input": "2021-07-03T09:48:59.051991Z",
          "iopub.status.idle": "2021-07-03T09:49:25.536901Z",
          "shell.execute_reply.started": "2021-07-03T09:48:59.051947Z",
          "shell.execute_reply": "2021-07-03T09:49:25.536047Z"
        },
        "trusted": true,
        "id": "5stcEtTQ0o75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_compare_df = pd.DataFrame({'Xgt':df_train_x['Xgt'].values, 'Xpred':pred_valid_x,\n",
        "                               'Ygt':df_train_y['Ygt'].values, 'Ypred':pred_valid_y,\n",
        "                                'Zgt':df_train_z['Zgt'].values, 'Zpred':pred_valid_z})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:49:43.082385Z",
          "iopub.execute_input": "2021-07-03T09:49:43.082741Z",
          "iopub.status.idle": "2021-07-03T09:49:43.090405Z",
          "shell.execute_reply.started": "2021-07-03T09:49:43.082711Z",
          "shell.execute_reply": "2021-07-03T09:49:43.089314Z"
        },
        "trusted": true,
        "id": "EyqwEg_R0o75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_compare_df[['Zgt', 'Zpred']].plot(figsize=(16,8))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:49:44.018524Z",
          "iopub.execute_input": "2021-07-03T09:49:44.018894Z",
          "iopub.status.idle": "2021-07-03T09:49:44.323168Z",
          "shell.execute_reply.started": "2021-07-03T09:49:44.018862Z",
          "shell.execute_reply": "2021-07-03T09:49:44.322051Z"
        },
        "trusted": true,
        "id": "6ouMPSkw0o75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_compare_df[['Ygt', 'Ypred']].plot(figsize=(16,8))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:49:44.545135Z",
          "iopub.execute_input": "2021-07-03T09:49:44.545517Z",
          "iopub.status.idle": "2021-07-03T09:49:44.804916Z",
          "shell.execute_reply.started": "2021-07-03T09:49:44.545481Z",
          "shell.execute_reply": "2021-07-03T09:49:44.80383Z"
        },
        "trusted": true,
        "id": "lOVfrOj50o75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that, gt and pre is close to each other."
      ],
      "metadata": {
        "id": "allccfvW0o75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xyz -> lng, lat\n",
        "lng_gt, lat_gt, _ = ECEF_to_WGS84(val_compare_df['Xgt'].values,val_compare_df['Ygt'].values,val_compare_df['Zgt'].values)\n",
        "lng_pred, lat_pred, _ = ECEF_to_WGS84(val_compare_df['Xpred'].values,val_compare_df['Ypred'].values,val_compare_df['Zpred'].values)\n",
        "lng_test_pred, lat_test_pred, _ = ECEF_to_WGS84(pred_test_x, pred_test_y, pred_test_z)\n",
        "\n",
        "    \n",
        "val_compare_df['latDeg_gt'] = lat_gt\n",
        "val_compare_df['lngDeg_gt'] = lng_gt\n",
        "val_compare_df['latDeg_pred'] = lat_pred\n",
        "val_compare_df['lngDeg_pred'] = lng_pred\n",
        "test_pred_df = pd.DataFrame({'latDeg':lat_test_pred, 'lngDeg':lng_test_pred})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:49:49.087272Z",
          "iopub.execute_input": "2021-07-03T09:49:49.08764Z",
          "iopub.status.idle": "2021-07-03T09:49:49.10913Z",
          "shell.execute_reply.started": "2021-07-03T09:49:49.087609Z",
          "shell.execute_reply": "2021-07-03T09:49:49.10803Z"
        },
        "trusted": true,
        "id": "U_hvz9Oo0o76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From：https://www.kaggle.com/emaerthin/demonstration-of-the-kalman-filter\n",
        "def calc_haversine(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"Calculates the great circle distance between two points\n",
        "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
        "    \"\"\"\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
        "\n",
        "    c = 2 * np.arcsin(a**0.5)\n",
        "    dist = 6_367_000 * c\n",
        "    return dist"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:49:55.351553Z",
          "iopub.execute_input": "2021-07-03T09:49:55.351898Z",
          "iopub.status.idle": "2021-07-03T09:49:55.358654Z",
          "shell.execute_reply.started": "2021-07-03T09:49:55.351869Z",
          "shell.execute_reply": "2021-07-03T09:49:55.357662Z"
        },
        "trusted": true,
        "id": "BtqmIg5c0o76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline vs. GT\n",
        "lat_lng_df_train['dist'] = calc_haversine(lat_lng_df_train.latDeg_gt, lat_lng_df_train.lngDeg_gt, \n",
        "                                lat_lng_df_train.latDeg_bl, lat_lng_df_train.lngDeg_bl)\n",
        "print('dist_50:',np.percentile(lat_lng_df_train['dist'],50) )\n",
        "print('dist_95:',np.percentile(lat_lng_df_train['dist'],95) )\n",
        "print('avg_dist_50_95:',(np.percentile(lat_lng_df_train['dist'],50) + np.percentile(lat_lng_df_train['dist'],95))/2)\n",
        "print('avg_dist:', lat_lng_df_train['dist'].mean())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:49:55.917737Z",
          "iopub.execute_input": "2021-07-03T09:49:55.918166Z",
          "iopub.status.idle": "2021-07-03T09:49:55.94387Z",
          "shell.execute_reply.started": "2021-07-03T09:49:55.91813Z",
          "shell.execute_reply": "2021-07-03T09:49:55.943031Z"
        },
        "trusted": true,
        "id": "1fnGIOoh0o76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMU Prediction vs. GT\n",
        "val_compare_df['dist'] = calc_haversine(val_compare_df.latDeg_gt, val_compare_df.lngDeg_gt, \n",
        "                                val_compare_df.latDeg_pred, val_compare_df.lngDeg_pred)\n",
        "# IMU预测vsGT（多collection）\n",
        "print('dist_50:',np.percentile(val_compare_df['dist'],50) )\n",
        "print('dist_95:',np.percentile(val_compare_df['dist'],95) )\n",
        "print('avg_dist_50_95:',(np.percentile(val_compare_df['dist'],50) + np.percentile(val_compare_df['dist'],95))/2)\n",
        "print('avg_dist:', val_compare_df['dist'].mean())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:49:59.171732Z",
          "iopub.execute_input": "2021-07-03T09:49:59.172231Z",
          "iopub.status.idle": "2021-07-03T09:49:59.19391Z",
          "shell.execute_reply.started": "2021-07-03T09:49:59.172197Z",
          "shell.execute_reply": "2021-07-03T09:49:59.193152Z"
        },
        "trusted": true,
        "id": "RBhEsxXa0o76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_trafic(df, center, zoom=15):\n",
        "    fig = px.scatter_mapbox(df,\n",
        "                            \n",
        "                            # Here, plotly gets, (x,y) coordinates\n",
        "                            lat=\"latDeg\",\n",
        "                            lon=\"lngDeg\",\n",
        "                            \n",
        "                            #Here, plotly detects color of series\n",
        "                            color=\"phoneName\",\n",
        "                            labels=\"phoneName\",\n",
        "                            \n",
        "                            zoom=zoom,\n",
        "                            center=center,\n",
        "                            height=600,\n",
        "                            width=800)\n",
        "    fig.update_layout(mapbox_style='stamen-terrain')\n",
        "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
        "    fig.update_layout(title_text=\"GPS trafic\")\n",
        "    fig.show()\n",
        "    \n",
        "def visualize_collection(df):\n",
        "    target_df = df\n",
        "    lat_center = target_df['latDeg'].mean()\n",
        "    lng_center = target_df['lngDeg'].mean()\n",
        "    center = {\"lat\":lat_center, \"lon\":lng_center}\n",
        "    \n",
        "    visualize_trafic(target_df, center)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:50:05.580653Z",
          "iopub.execute_input": "2021-07-03T09:50:05.581162Z",
          "iopub.status.idle": "2021-07-03T09:50:05.588855Z",
          "shell.execute_reply.started": "2021-07-03T09:50:05.58113Z",
          "shell.execute_reply": "2021-07-03T09:50:05.587821Z"
        },
        "trusted": true,
        "id": "2HDJTUuw0o76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization: Train dataset\n",
        "cname = '2021-04-29-US-SJC-2'\n",
        "pname = 'SamsungS20Ultra'\n",
        "# IMU Prediciton\n",
        "tmp0 = val_compare_df.copy()\n",
        "tmp0.rename(columns={'latDeg_pred':'latDeg', 'lngDeg_pred':'lngDeg'}, inplace=True)\n",
        "tmp0['phoneName'] = [cname + '_' + pname + '_imu_pred' for i in range(len(tmp0))]\n",
        "# GT\n",
        "tmp1 = val_compare_df.copy()\n",
        "tmp1.rename(columns={'latDeg_gt':'latDeg', 'lngDeg_gt':'lngDeg'}, inplace=True)\n",
        "tmp1['phoneName'] = [cname + '_' + pname + '_gt' for i in range(len(tmp1))]\n",
        "# Baseline\n",
        "tmp2 = lat_lng_df_train.copy()\n",
        "tmp2.rename(columns={'latDeg_bl':'latDeg', 'lngDeg_bl':'lngDeg'}, inplace=True)\n",
        "tmp2['phoneName'] = [cname + '_' + pname + '_bl_pred' for i in range(len(tmp2))]\n",
        "\n",
        "tmp = pd.concat([tmp0, tmp1, tmp2])\n",
        "visualize_collection(tmp)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:51:09.564618Z",
          "iopub.execute_input": "2021-07-03T09:51:09.565037Z",
          "iopub.status.idle": "2021-07-03T09:51:10.965084Z",
          "shell.execute_reply.started": "2021-07-03T09:51:09.565004Z",
          "shell.execute_reply": "2021-07-03T09:51:10.962295Z"
        },
        "trusted": true,
        "id": "-0sQTRe90o76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization:: Test dataset\n",
        "cname = '2021-04-29-US-SJC-3'\n",
        "pname = 'SamsungS20Ultra'\n",
        "tmp3 = test_pred_df.copy()\n",
        "tmp3['phoneName'] = cname_test + '_' + pname_test + '_imu_pred' \n",
        "\n",
        "tmp4 = bl_tst_df.iloc[bl_tst_df[bl_tst_df['phone']==cname_test + '_' + pname_test].index[window_size:],3:5].copy()\n",
        "tmp4['phoneName'] = cname_test + '_' + pname_test + '_bl_pred' \n",
        "\n",
        "tmp5 = pd.concat([tmp3, tmp4])\n",
        "visualize_collection(tmp5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:51:31.857343Z",
          "iopub.execute_input": "2021-07-03T09:51:31.857771Z",
          "iopub.status.idle": "2021-07-03T09:51:31.96951Z",
          "shell.execute_reply.started": "2021-07-03T09:51:31.857735Z",
          "shell.execute_reply": "2021-07-03T09:51:31.968585Z"
        },
        "trusted": true,
        "id": "Cxcn8Y550o76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Submission"
      ],
      "metadata": {
        "id": "yp4o3x7M0o77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bl_tst_df.iloc[bl_tst_df[bl_tst_df['phone']==cname_test + '_' + pname_test].index[window_size:],3] = test_pred_df['latDeg'].values\n",
        "bl_tst_df.iloc[bl_tst_df[bl_tst_df['phone']==cname_test + '_' + pname_test].index[window_size:],4] = test_pred_df['lngDeg'].values\n",
        "\n",
        "# bl_tst_df.to_csv('../submit/imu_baseline_locations_test.csv', index = False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-03T09:51:55.358474Z",
          "iopub.execute_input": "2021-07-03T09:51:55.359044Z",
          "iopub.status.idle": "2021-07-03T09:51:55.390987Z",
          "shell.execute_reply.started": "2021-07-03T09:51:55.35901Z",
          "shell.execute_reply": "2021-07-03T09:51:55.390056Z"
        },
        "trusted": true,
        "id": "mHcWnc_R0o77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code is just a template. I cannot promise it could improve a lot for you because i didn't publish my entire code (which contains some tricks). However, i hope my code could inspire you how to use GNSS log data. <br>\n",
        "\n",
        "On the other hand, i am seeking for a nice teammate, here is my basic infomation:\n",
        "1. I am fresh of Kaggle, but attend some competitions in China before.\n",
        "2. I am Data Analyst from OPPO for more than one year (well, indoor game uses our phone's data).\n",
        "3. I am graduated from University of Manchester, UK. I guess my English can handle the normal communication.\n",
        "4. I have another teammate from china, too. (he is nice)\n",
        "5. I can use 1-3 hrs/day for playing this competition but the weekend i got one day for fee.\n",
        "\n",
        "What I hope:\n",
        "1. You are Top 50 or related experience about phone locating.\n",
        "2. You have time and energy to keep working on the game.\n",
        "3. You are like to publish the code when we finished this game.\n",
        "4. Most importance!!! you have great ideas!\n",
        "\n",
        "If you want to join us, feel free to contact me. My email: **alvinai9603@outlook.com**<br>\n",
        "\n",
        "Thanks."
      ],
      "metadata": {
        "id": "izTcGoww0o77"
      }
    }
  ]
}